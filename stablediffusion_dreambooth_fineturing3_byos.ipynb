{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed034c1a-156a-4beb-9a38-af2894187994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nvidia-smi\n",
    "#!dpkg --print-architecture\n",
    "#!gcc -v\n",
    "#!cat /etc/issue\n",
    "!pip3 list|grep -i torch\n",
    "!pip3 list|grep -i cud\n",
    "!pip list|grep -i xformer\n",
    "#!python -m torch.utils.collect_env\n",
    "#!pip3 list|grep -i triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0639cab2-e673-49c3-bac9-4e9627747172",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ./training && git clone https://github.com/qingyuan18/sd_dreambooth_extension.git ./extensions/sd_dreambooth_extension/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c5d0d3-a2f6-4911-9aa9-2f3c14fa7a39",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r ./training/extensions/sd_dreambooth_extension/requirements.txt\n",
    "#!pip install -r ./training/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f02d246-7a87-4bac-a609-9fbd2c4b7e80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! apt-get update\n",
    "! apt-get install --assume-yes apt-utils -y\n",
    "\n",
    "! apt update\n",
    "! echo \"Y\"|apt install vim\n",
    "! apt install wget git -y\n",
    "! apt install libgl1-mesa-glx -y\n",
    "! pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eab0ef5-8fd9-47b7-82db-f3f3c3980eca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "!pip install ninja triton==2.0.0.dev20221120 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba707ec1-36f5-4683-9a0b-c9e6991f5aff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!export TORCH_CUDA_ARCH_LIST=\"7.5 8.0 8.6\" && export FORCE_CUDA=\"1\"&&git clone https://github.com/xieyongliang/xformers.git ./repositories/xformers && cd ./repositories/xformers && git submodule update --init --recursive && pip install -r requirements.txt && pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c14770-6b8a-41b8-9e94-e9321c2adefa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!echo \"Y\"|pip uninstall xformers==0.0.16rc425\n",
    "!echo \"Y\"|pip uninstall xformers==0.0.16.dev426\n",
    "#!pip install xformers==0.0.16.dev426"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7279d922-766c-4a71-8ed4-363467c9c817",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patching transformers to fix kwargs errors.\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n",
      "{'model_name': 'aws-trained-dreambooth-model', 'models_path': './model/', 'use_lora': False, 'use_cpu': False, 'lora_models_path': None, 'pretrained_model_name_or_path': 'ClueAI/ChatYuan-large-v1', 'pretrained_vae_name_or_path': None, 'revision': None, 'tokenizer_name': None, 'instance_data_dir': './images/', 'class_data_dir': './images/', 'instance_prompt': 'Erwin Rommel', 'class_prompt': 'a photo of Erwin Rommel', 'pad_tokens': False, 'with_prior_preservation': True, 'save_use_global_counts': False, 'save_use_epochs': True, 'prior_loss_weight': 0.5, 'num_class_images': 0, 'output_dir': 'text-inversion-model', 'seed': -1, 'resolution': 512, 'center_crop': False, 'train_text_encoder': 'True', 'train_batch_size': 1, 'sample_batch_size': 1, 'num_train_epochs': 1, 'max_train_steps': 600, 'epoch': 0, 'save_steps': 600, 'gradient_accumulation_steps': 1, 'gradient_checkpointing': True, 'learning_rate': 5e-06, 'scale_lr': False, 'lr_scheduler': 'constant', 'lr_warmup_steps': 100, 'use_8bit_adam': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'push_to_hub': False, 'hub_token': None, 'hub_model_id': None, 'logging_dir': 'logs', 'mixed_precision': 'fp16', 'not_cache_latents': 'True', 'hflip': False, 'local_rank': -1, 'concepts_list': [{'instance_prompt': 'Erwin Rommel', 'class_prompt': 'a photo of Erwin Rommel', 'instance_data_dir': './images/', 'class_data_dir': './images/', 'num_class_images': 0, 'instance_token': '', 'class_token': '', 'class_negative_prompt': '', 'class_guidance_scale': 7.5, 'class_infer_steps': 60}], 'use_ema': True, 'max_token_length': 75, 'half_model': False, 'attention': 'xformers', 'shuffle_tags': False}\n",
      "Replace CrossAttention.forward to use xformers\n",
      "Checking concept: {'instance_prompt': 'Erwin Rommel', 'class_prompt': 'a photo of Erwin Rommel', 'instance_data_dir': './images/', 'class_data_dir': './images/', 'num_class_images': 0, 'instance_token': '', 'class_token': '', 'class_negative_prompt': '', 'class_guidance_scale': 7.5, 'class_infer_steps': 60}\n",
      "Concept requires 0 images.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py\", line 264, in hf_raise_for_status\n",
      "    response.raise_for_status()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/requests/models.py\", line 943, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/ClueAI/ChatYuan-large-v1/resolve/main/tokenizer/config.json\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/utils/hub.py\", line 409, in cached_file\n",
      "    resolved_file = hf_hub_download(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py\", line 124, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/huggingface_hub/file_download.py\", line 1105, in hf_hub_download\n",
      "    metadata = get_hf_file_metadata(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py\", line 124, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/huggingface_hub/file_download.py\", line 1440, in get_hf_file_metadata\n",
      "    hf_raise_for_status(r)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py\", line 282, in hf_raise_for_status\n",
      "    raise EntryNotFoundError(message, response) from e\n",
      "huggingface_hub.utils._errors.EntryNotFoundError: 404 Client Error. (Request ID: Root=1-63dcbf17-3ce367fc69ec407d04ba547e)\n",
      "\n",
      "Entry Not Found for url: https://huggingface.co/ClueAI/ChatYuan-large-v1/resolve/main/tokenizer/config.json.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"./training/train.py\", line 1208, in <module>\n",
      "    main(args=args, memory_record={}, use_subdir=False, lora_model=None, lora_alpha=1.0, lora_txt_alpha=1.0, custom_model_name=\"\")\n",
      "  File \"./training/train.py\", line 569, in main\n",
      "    tokenizer = AutoTokenizer.from_pretrained(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py\", line 597, in from_pretrained\n",
      "    config = AutoConfig.from_pretrained(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py\", line 809, in from_pretrained\n",
      "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/configuration_utils.py\", line 559, in get_config_dict\n",
      "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/configuration_utils.py\", line 614, in _get_config_dict\n",
      "    resolved_config_file = cached_file(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/utils/hub.py\", line 454, in cached_file\n",
      "    raise EnvironmentError(\n",
      "OSError: ClueAI/ChatYuan-large-v1 does not appear to have a file named tokenizer/config.json. Checkout 'https://huggingface.co/ClueAI/ChatYuan-large-v1/main' for available files.\n"
     ]
    }
   ],
   "source": [
    "!export PYTORCH_CUDA_ALLOC_CONF='max_split_size_mb:32'&& python ./training/train.py \\\n",
    "--attention xformers  \\\n",
    "--class_data_dir \"./images/\"  \\\n",
    "--class_prompt \"a photo of Erwin Rommel\" \\\n",
    "--gradient_accumulation_steps 1 \\\n",
    "--gradient_checkpointing True \\\n",
    "--instance_data_dir \"./images/\" \\\n",
    "--instance_prompt \"Erwin Rommel\" \\\n",
    "--learning_rate 5e-06 \\\n",
    "--lr_scheduler constant  \\\n",
    "--lr_warmup_steps 100  \\\n",
    "--max_train_steps 600  \\\n",
    "--mixed_precision fp16  \\\n",
    "--model_name aws-trained-dreambooth-model \\\n",
    "--models_path \"./model/\"  \\\n",
    "--not_cache_latents True  \\\n",
    "--num_class_images 0   \\\n",
    "--pretrained_model_name_or_path \"stabilityai/stable-diffusion-2\" \\\n",
    "--prior_loss_weight 0.5 \\\n",
    "--resolution 512  \\\n",
    "--sample_batch_size 1 \\\n",
    "--save_steps 600  \\\n",
    "--train_batch_size 1 \\\n",
    "--train_text_encoder True \\\n",
    "--use_ema True \\\n",
    "--with_prior_preservation True \\\n",
    "--save_use_epochs False \\\n",
    "--use_8bit_adam True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f010944f-e0fe-472a-84c5-6e4609c36b69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)  # 查看torch当前版本号\n",
    "print(torch.version.cuda)  # 编译当前版本的torch使用的cuda版本号\n",
    "print(torch.cuda.is_available())  # 查看当前cuda是否可用于当前版本的Torch，如果输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac85d9e-e504-4d3f-828f-e0bf94bfa4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.12 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/pytorch-1.12-gpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
